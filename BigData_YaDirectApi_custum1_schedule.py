import requests
from datetime import datetime, date, timedelta

from airflow import DAG
from airflow.utils.dates import days_ago
from airflow.operators.python_operator import PythonOperator
from airflow.contrib.operators.ssh_operator import SSHOperator

# Ð”Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð¹ Ð½Ð° Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ.
# Ð»Ð°Ð³ Ð² 1 Ð´ÐµÐ½ÑŒ Ð¿Ð¾ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸ÑŽ Ð·Ð°ÐºÐ°Ð·Ñ‡Ð¸ÐºÐ°
# start_date = end_date - Ð²Ñ‹Ð³Ñ€ÑƒÐ¶ÐµÐ¼ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¹ Ð´Ð°Ñ‚Ðµ Ð·Ð° Ñ€Ð°Ð·
start_date_v = str(datetime.date(datetime.today()) - timedelta(days=1))
end_date_v = str(datetime.date(datetime.today()) - timedelta(days=1))

# BASH ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ‚Ð¾Ð»ÐºÐ°ÑŽÑ‚ ÑÐºÑ€Ð¸Ð¿Ñ‚Ñ‹ Ð½Ð° ÑÑ‚Ð¾Ñ€Ð¾Ð½Ðµ 08 Ñ…Ð¾ÑÑ‚Ð° 
bash_clear_tmp = '/usr/bin/python3 /home/bdataadmin/airflowYaDirect/skripts/clear_custum1_txt.py'
bash_clear_hdfs = '/usr/bin/bash /home/bdataadmin/airflowYaDirect/skripts/Ñheck_hdfs_custom1_txt.sh '

bash_download_custum1_txt = f'/usr/bin/python3 /home/bdataadmin/airflowYaDirect/skripts/getYaDirect_custum1.py {start_date_v}'
bash_preprocessing_txt = '/usr/bin/python3 /home/bdataadmin/airflowYaDirect/skripts/checking_custum1_txt.py'
bash_hdfs_put_bigTxt = '/usr/bin/bash hdfs dfs -put /home/bdataadmin/airflowYaDirect/txt_final/YaDirect_custum1.txt /data/yaDirect/txt_custom_report_1 '

bash_start_pySpark_basic_orc = '/usr/bin/bash /home/bdataadmin/airflowYaDirect/skripts/start_pySpark_YaDirect_custom1.sh '

# DAG ÑƒÐ¿Ð°Ð» ðŸ›‘
# DAG Ð¾Ñ‚Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ âœ…
def tlgrm(message):
    """
    Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ñ‡ÐµÑ€ÐµÐ· Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð¼ Ð±Ð¾Ñ‚ ÑˆÐ»ÐµÑ‚ Ð² Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼Ð¼ Ð±ÐµÑÐµÐ´Ñƒ
    Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ñ‹ Ð¾Ð± ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸ Ð¸Ð»Ð¸ Ð½Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ÑÑ‚Ð¸ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ DAG-Ð°.
    Ð‘ÐµÑÐµÐ´Ð° Ð½Ð°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ: AFLT_BigDataReports
    """
    token = "BOT_ID:BOT_TOKEN"
    url = "https://api.telegram.org/bot"
    channel_id = "-100PRESS_YOUR_CHANNEL_ID"
    url += token
    method = url + "/sendMessage"

    try:
        r = requests.post(method,
                          data={
                              "chat_id": channel_id,
                              "text": message},
                          #                          proxies=proxy,
                          timeout=30)
        print(r.json())
    except requests.exceptions.ConnectionError:
        print("Ð˜ÑÐºÐ»_1")
        return False


default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 8, 25),
    'retries': 0
}


# Ð•ÑÐ»Ð¸ Ð½Ð° ÐºÐ°ÐºÐ¾Ð¼-Ñ‚Ð¾ ÑƒÐ·Ð»Ðµ DAG-Ð° Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð¿Ð¾ÑˆÐ»Ð¾ Ð½Ðµ Ñ‚Ð°Ðº - ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ñ‡Ñ‚Ð¾ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ° Ð½ÐµÑƒÑÐ¿ÐµÑˆÐ½Ð°
# Ð¸ Ð´Ð»Ñ Ð´Ð°Ð½Ð½Ð¾Ð¹ Ð´Ð°Ñ‚Ñ‹ Ð½ÑƒÐ¶Ð½Ð¾ Ð½Ð°Ñ‡Ð¸Ð½Ð°Ñ‚ÑŒ Ð²ÑÐµ ÑÐ½Ð°Ñ‡Ð°Ð»Ð°. 
# Ð¡ÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‚ Ð¿Ð°Ñ€Ñ‹ DAG-Ð¾Ð²: 1)Ñ Ð²Ñ‹Ð±Ð¾Ñ€Ð¾Ð¼ Ð´Ð°Ñ‚Ñ‹ Ð´Ð»Ñ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸
# 2) Ð¸ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð½Ð¾Ð¼ Ð½Ð° Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ - ÐºÐ¾Ñ‚Ñ€Ñ€Ñ‹Ð¹ Ð»ÑƒÑ‡ÑˆÐµ Ð½Ðµ Ñ‚Ñ€Ð¾Ð³Ð°Ñ‚ÑŒ.
with DAG(dag_id='BigData_YaDirect_custum1_schedule',
         tags=["ETL Ð½Ð° Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ð¸"],
         default_args=default_args,
         schedule_interval='15 21 * * * ',    # ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ Ð² 21:15 ÑƒÑ‚Ñ€Ð°, Ð½Ð¾ Ñ‚Ðº UTC +3 Ñ‡Ð°ÑÐ°, Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ Ð² 00:15 ÑƒÑ‚Ñ€Ð°
         start_date=days_ago(1)
         ) as dag:

    task_clear_tmp_1 = SSHOperator(
        task_id='task_clear_tmp_1',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_1 = SSHOperator(
        task_id='task_clear_hdfs_1',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    download_custum1 = SSHOperator(
        task_id='task_download_custum1',
        ssh_conn_id="ssh_08",
        command=bash_download_custum1_txt,
        dag=dag
    )

    task_preprocessing_txt = SSHOperator(
        task_id='task_preprocessing_txt',
        ssh_conn_id="ssh_08",
        command=bash_preprocessing_txt,
        dag=dag
    )

    task_move_bigTxt = SSHOperator(
        task_id='task_move_bigTxt',
        ssh_conn_id="ssh_08",
        command=bash_hdfs_put_bigTxt,
        dag=dag
    )

    task_start_pySpark_Basic_orc = SSHOperator(
        task_id='task_start_pySpark_Basic_orc',
        ssh_conn_id="ssh_08",
        command=bash_start_pySpark_basic_orc,
        dag=dag
    )

    task_clear_tmp_2 = SSHOperator(
        task_id='task_clear_tmp_2',
        ssh_conn_id="ssh_08",
        command=bash_clear_tmp,
        dag=dag
    )

    task_clear_hdfs_2 = SSHOperator(
        task_id='task_clear_hdfs_2',
        ssh_conn_id="ssh_08",
        command=bash_clear_hdfs,
        dag=dag
    )

    tlgrm_allSuccess = PythonOperator(
        task_id='tlgrm_allSuccess',
        python_callable=tlgrm,
        dag=dag,
        trigger_rule='all_success',
        op_kwargs={
            'message': f"ÐžÑ‚Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ âœ… - DAG YaDirect_custum1_schedule_{start_date_v}_{end_date_v}"}
    )

    tlgrm_oneFailed = PythonOperator(
        task_id='tlgrm_oneFailed',
        python_callable=tlgrm,
        dag=dag,
        trigger_rule='one_failed',
        op_kwargs={
            'message': f"Ð£Ð¿Ð°Ð» ðŸ›‘ - DAG YaDirect_custum1_schedule_{start_date_v}_{end_date_v}"}
    )

(task_clear_tmp_1 >> task_clear_hdfs_1 >> download_custum1 >> task_preprocessing_txt >> task_move_bigTxt >> task_start_pySpark_Basic_orc >> task_clear_tmp_2 >> task_clear_hdfs_2 >> [tlgrm_allSuccess, tlgrm_oneFailed])
